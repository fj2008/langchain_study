# 랭체인 스터디 3주차 (~ CH01 까지)

## 공부 출처 https://wikidocs.net/book/14314

## 범위 5~6장

# Memory
기본적으로 어떠한 사전 정보를 미리 메모리에 띄워 놓고 이를 어떻게 활용하는가에 대한 방식들을 나열하는 장이다.
1. Memory 기능을 왜 사용하는가?

LangChain의 기본 설계는 “멀티턴 대화”나 “상태를 가진 작업”을 다루기 위한 것입니다.
그런데 일반 LLM (ex. GPT-4) 은 한번 요청할 때마다 과거 문맥을 기억하지 못합니다.
그래서 매번 과거 대화를 “다시” 입력해줘야 하는 문제가 있어요.

Memory는 이 문제를 해결하기 위해:
	•	대화 내역을 기억하거나
	•	사용자의 이전 입력,
	•	모델의 이전 응답
등을 저장해서 다음 번 요청에 자동으로 붙여주는 기능입니다.

즉, “상태 유지” 를 위해 Memory가 필요합니다.

2. Memory를 사용하는 상황

다음과 같은 상황에서 Memory를 사용합니다:
	•	챗봇
→ 사용자와 여러 턴(turn)을 오가며 대화할 때, 앞서 한 말을 기억해야 자연스럽게 이어갈 수 있습니다.
	•	Agent 시스템
→ 여러 번 행동을 하면서 중간 결과들을 기억하거나, 목표를 재설정할 때.
	•	사용자 맞춤형 서비스
→ 사용자 프로필, 과거 행동(예: 검색 기록, 선택지 등)을 기억하고 다음 답변에 반영할 때.
	•	Q&A 시스템
→ 사용자가 한 시리즈의 질문을 이어서 할 때, 앞 질문의 맥락을 기억해야 할 때.

## 1-1 ConversationBufferMemory 
1. save_context 로 대화 내용을 기억하게 할 수 있음
2. 1에서 저장한대화내용을 llm에 memory로 넣어서 미리 출력할 대답을 어느정도 설정하게 할 수 있음
3. chain에 적용
  ```python
  from langchain_openai import ChatOpenAI
  from langchain.chains import ConversationChain

  # LLM 모델을 생성합니다.
  llm = ChatOpenAI(temperature=0, model_name="gpt-4o")

  # ConversationChain을 생성합니다.
  conversation = ConversationChain(
      # ConversationBufferMemory를 사용합니다.
      llm=llm,
      memory=ConversationBufferMemory(), # 여기서 save_context로 저장한 대화내용 memory에 띄운다.
  )
  # 대화를 시작합니다.
  response = conversation.predict(
      input="안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?"
  )
  print(response)
  ```
## 1-2 ConversationBufferWindowMemory
1-1 과 비슷한 내용이나 다른점은 시간이 지남에 따라 대화의 상호작용 목록을 유지한다, 즉 모든 대화내용을 활용하는 것이 아닌 최근 K(설정가능)개의 상호작용만 사용한다. 이는 버퍼가 너무 커지는 것을 방지한다.

## 1-3 ConversationTokenBufferMemory
1-1 과 비슷한 내용, 다른점은 최근 대화의 히스토리를 버퍼를 메모리에 보관하고, 대화의 개수가 아닌 토큰 길이를 사용하여 대화내용을 flush할 시기를 결정한다.

- 예시
```python
from langchain.memory import ConversationTokenBufferMemory
from langchain_openai import ChatOpenAI


# LLM 모델 생성
llm = ChatOpenAI(model_name="gpt-4o")

# 메모리 설정
memory = ConversationTokenBufferMemory(
    llm=llm, max_token_limit=150, return_messages=True  # 최대 토큰 길이를 150개로 제한
)
```

## 1-4 ConversationEntityMemory
엔티티 메모리는 대화에서 특정 엔티티에 대한 주어진 사실을 기억한다.

## 1-5 ConversationKGMemory
그래프를 활용해서 서로 다른 개체간의 관계를 이해하는 데 도움을 주고 복잡한 연결망과 역사적 맥락을 기반으로 대응하는 능력을향상시킨다.


## 1-6 VectorStoreRetrieverMemory
save_context 를 할때 OpenAIEmbeddings() 를 활용해서 백터를 활용하는것,
대화내용을 백터로 기억하여 서빙하는것.

## 1-7 LCEl 대화내용 기억하기 (메모리 추가)
임의의 체인에 메모리를 추가하는 방법.

대화내용을 저장할 메모리인 `ConversationBufferMemory` 생성하고 `return_messages` 매개변수를 `True`로 설정하여, 생성된 인스턴스가 메시지를 반환하도록 합니다.
- `memory_key` 설정: 추후 Chain 의 `prompt` 안에 대입될 key 입니다. 변경하여 사용할 수 있습니다.

